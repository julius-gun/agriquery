{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Question Answering Demonstration\n",
    "\n",
    "This notebook allows you to ask a question against a knowledge base stored in ChromaDB.\n",
    "\n",
    "**Functionality:**\n",
    "1. Takes your question as input.\n",
    "2. Automatically finds the correct ChromaDB collection based on parameters in `config.json` (language, chunk size, overlap size).\n",
    "3. Retrieves the most relevant context chunks from the database.\n",
    "4. Displays the retrieved context.\n",
    "5. **Optionally:** Queries a specified LLM (from `config.json`) with the question and context.\n",
    "6. **Optionally:** Evaluates the LLM's answer against an expected answer you provide.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Run Location:** Make sure you run this notebook from the `p_llm_manual/RAG` directory so it can find the necessary modules (`utils`, `llm_connectors`, etc.) and the `config.json` file.\n",
    "2. **Configure Below:** Modify the variables in the 'User Configuration' cell below (especially `your_question`).\n",
    "3. **Run Cells:** Execute the cells sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original working directory: c:\\Users\\pc.WINS-22MAIN\\p_llm_manual\\RAG\n",
      "'C:\\Users\\pc.WINS-22MAIN\\p_llm_manual\\RAG' already in sys.path\n",
      "Successfully imported project modules.\n"
     ]
    }
   ],
   "source": [
    "# --- Imports and Path Setup ---\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import chromadb\n",
    "import pathlib\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "# Add the project root directory (p_llm_manual/RAG) to the Python path\n",
    "print(f\"Original working directory: {os.getcwd()}\")\n",
    "project_root = pathlib.Path(os.getcwd()).resolve() # Assumes notebook is run from RAG directory\n",
    "if project_root.name != 'RAG':\n",
    "    print(\"WARNING: Notebook might not be running from the 'p_llm_manual/RAG' directory. Trying to adjust path...\")\n",
    "    # Attempt to find the RAG directory if nested\n",
    "    current_path = project_root\n",
    "    while current_path.name != 'RAG' and current_path.parent != current_path:\n",
    "        current_path = current_path.parent\n",
    "    if current_path.name == 'RAG':\n",
    "        project_root = current_path\n",
    "        print(f\"Adjusted project root to: {project_root}\")\n",
    "    else:\n",
    "        print(f\"ERROR: Could not reliably determine the project root ('RAG' directory). Imports might fail.\")\n",
    "        # Fallback to assuming current dir's parent is RAG if structure is known\n",
    "        # project_root = pathlib.Path(os.getcwd()).resolve().parent # Example adjustment\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"Added '{project_root}' to sys.path\")\n",
    "else:\n",
    "    print(f\"'{project_root}' already in sys.path\")\n",
    "\n",
    "# --- Project Imports ---\n",
    "try:\n",
    "    from utils.config_loader import ConfigLoader\n",
    "    from llm_connectors.llm_connector_manager import LLMConnectorManager\n",
    "    from llm_connectors.base_llm_connector import BaseLLMConnector\n",
    "    from retrieval_pipelines.embedding_retriever import EmbeddingRetriever\n",
    "    from evaluation.evaluator import Evaluator\n",
    "    print(\"Successfully imported project modules.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Failed to import necessary project modules: {e}\")\n",
    "    print(f\"Project Root: {project_root}\")\n",
    "    print(f\"Sys Path: {sys.path}\")\n",
    "    print(\"Ensure the notebook is run from the 'p_llm_manual/RAG' directory or the path setup is correct.\")\n",
    "    # Raise the error to stop execution if imports fail\n",
    "    raise\n",
    "\n",
    "# --- Helper Function (from ask_question.py) ---\n",
    "def find_llm_type(\n",
    "    model_name: str, llm_configs: Dict[str, Dict[str, Any]]\n",
    ") -> Optional[str]:\n",
    "    \"\"\"Finds the type ('ollama', 'gemini', etc.) of a given model name from the config.\"\"\"\n",
    "    for type_key, models in llm_configs.items():\n",
    "        if model_name in models:\n",
    "            return type_key\n",
    "    return None\n",
    "\n",
    "# --- Constants ---\n",
    "DEFAULT_CONFIG_NAME = \"config.json\"\n",
    "DEFAULT_DB_DIR_NAME = \"chroma_db\"\n",
    "DEFAULT_EVALUATOR_LLM_TYPE = \"ollama\" # Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration Summary ---\n",
      "Question: What is the hopper weight without hopper cover in kg of the Exacta-TLX GEOSPREAD 3225?\n",
      "LLM Model for Answering: qwen2.5_7B-128k\n",
      "Evaluate Answer: True\n",
      "Config File: config.json\n",
      "Database Directory: chroma_db\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- User Configuration ---\n",
    "\n",
    "# 1. The question you want to ask\n",
    "your_question = input(\"Enter your question: \") # Get question interactively\n",
    "# Example: your_question = \"What is the maximum pressure?\"\n",
    "\n",
    "# 2. (Optional) Specify the LLM to use for answering (must be a key in config.json -> llm_models)\n",
    "# Set to None to only retrieve context without querying an LLM.\n",
    "llm_model_to_use = \"qwen2.5_7B-128k\" # Example: Use qwen2.5_7B-128k\n",
    "# llm_model_to_use = None # Example: Only retrieve context\n",
    "\n",
    "# 3. (Optional) Set to True if you want to evaluate the LLM's answer (requires llm_model_to_use to be set)\n",
    "evaluate_answer_flag = True # Example: Evaluate the answer\n",
    "# evaluate_answer_flag = False # Example: Do not evaluate\n",
    "\n",
    "# 4. Configuration file name (relative to project root)\n",
    "config_file_name = DEFAULT_CONFIG_NAME\n",
    "# config_file_name = \"config_fast.json\" # If using a different config\n",
    "\n",
    "# 5. ChromaDB directory name (relative to project root)\n",
    "db_dir_name = DEFAULT_DB_DIR_NAME\n",
    "\n",
    "# --- Print chosen configuration ---\n",
    "print(\"--- Configuration Summary ---\")\n",
    "print(f\"Question: {your_question}\")\n",
    "print(f\"LLM Model for Answering: {llm_model_to_use if llm_model_to_use else 'None (Context Retrieval Only)'}\")\n",
    "print(f\"Evaluate Answer: {evaluate_answer_flag if llm_model_to_use else 'N/A'}\")\n",
    "print(f\"Config File: {config_file_name}\")\n",
    "print(f\"Database Directory: {db_dir_name}\")\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading configuration...\n",
      "[INFO] Configuration loaded successfully from C:\\Users\\pc.WINS-22MAIN\\p_llm_manual\\RAG\\config.json\n",
      "[INFO] Using language from config: 'english'\n",
      "[INFO] Using chunk size from config: 200\n",
      "[INFO] Using overlap size from config: 100\n",
      "[INFO] Using top-k from config: 3\n",
      "[INFO] Target ChromaDB collection name: 'english_manual_cs200_os100'\n"
     ]
    }
   ],
   "source": [
    "# --- Load Configuration and Determine Parameters ---\n",
    "print(\"[INFO] Loading configuration...\")\n",
    "config = None\n",
    "rag_params = {}\n",
    "language_configs = []\n",
    "llm_models_config = {}\n",
    "target_language = None\n",
    "collection_base_name = None\n",
    "chunk_size = None\n",
    "overlap_size = None\n",
    "top_k = 3 # Default top-k\n",
    "dynamic_collection_name = None\n",
    "\n",
    "config_path = project_root / config_file_name\n",
    "db_path = project_root / db_dir_name\n",
    "\n",
    "try:\n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n",
    "\n",
    "    config_loader = ConfigLoader(str(config_path))\n",
    "    config = config_loader.config\n",
    "    rag_params = config_loader.get_rag_parameters()\n",
    "    language_configs = config.get(\"language_configs\", [])\n",
    "    llm_models_config = config.get(\"llm_models\", {})\n",
    "    print(f\"[INFO] Configuration loaded successfully from {config_path}\")\n",
    "\n",
    "    # Determine Language (using first in config as default)\n",
    "    if language_configs:\n",
    "        lang_config = language_configs[0] # Use the first language defined\n",
    "        target_language = lang_config.get(\"language\")\n",
    "        collection_base_name = lang_config.get(\"collection_base_name\")\n",
    "        if not target_language or not collection_base_name:\n",
    "            raise ValueError(\"First language_config entry is missing 'language' or 'collection_base_name'.\")\n",
    "        print(f\"[INFO] Using language from config: '{target_language}'\")\n",
    "    else:\n",
    "        raise ValueError(\"No 'language_configs' found in configuration.\")\n",
    "\n",
    "    # Determine Chunk Size (using first from config's rag_parameters)\n",
    "    chunk_sizes_in_config = rag_params.get(\"chunk_sizes_to_test\", [])\n",
    "    if chunk_sizes_in_config:\n",
    "        chunk_size = chunk_sizes_in_config[0]\n",
    "        print(f\"[INFO] Using chunk size from config: {chunk_size}\")\n",
    "    else:\n",
    "        raise ValueError(\"'chunk_sizes_to_test' not found or empty in config's rag_parameters.\")\n",
    "\n",
    "    # Determine Overlap Size (using first from config's rag_parameters)\n",
    "    overlap_sizes_in_config = rag_params.get(\"overlap_sizes_to_test\", [])\n",
    "    if overlap_sizes_in_config:\n",
    "        overlap_size = overlap_sizes_in_config[0]\n",
    "        print(f\"[INFO] Using overlap size from config: {overlap_size}\")\n",
    "    else:\n",
    "        raise ValueError(\"'overlap_sizes_to_test' not found or empty in config's rag_parameters.\")\n",
    "\n",
    "    # Determine Top K (using value from config's rag_parameters or default)\n",
    "    top_k_config = rag_params.get(\"num_retrieved_docs\")\n",
    "    if top_k_config is not None:\n",
    "        top_k = top_k_config\n",
    "        print(f\"[INFO] Using top-k from config: {top_k}\")\n",
    "    else:\n",
    "        print(f\"[INFO] 'num_retrieved_docs' not found in config, using default top-k: {top_k}\")\n",
    "\n",
    "    # Construct Collection Name\n",
    "    dynamic_collection_name = f\"{collection_base_name}_cs{chunk_size}_os{overlap_size}\"\n",
    "    print(f\"[INFO] Target ChromaDB collection name: '{dynamic_collection_name}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load configuration or determine parameters: {e}\")\n",
    "    # Stop execution if config fails\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Attempting to connect to ChromaDB at: C:\\Users\\pc.WINS-22MAIN\\p_llm_manual\\RAG\\chroma_db\n",
      "[INFO] ChromaDB client initialized.\n",
      "[INFO] Attempting to get collection: 'english_manual_cs200_os100'\n",
      "[INFO] Successfully connected to collection 'english_manual_cs200_os100'. It contains 678 items.\n",
      "[INFO] Initializing embedding retriever...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00, 241.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Vectorizing question...\n",
      "[INFO] Question vectorized successfully.\n",
      "[INFO] Retrieving top 3 relevant documents...\n",
      "[INFO] Retrieval complete.\n",
      "\n",
      "==================== Retrieved Context ====================\n",
      "\n",
      "--- Document 1 (Distance: 0.6343) ---\n",
      "Getting familiar with the machine\n",
      "Technical specifications\n",
      "                                Exacta-TLX GEOSPREAD                                                                                                1875                                                                                                2550                                                                                                3225                                                                                                3900\n",
      "0                                            General                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "1                          Content of the hopper (l)                                                                                                1875                                                                                                2550                                                                                                3225                                                                                                3900\n",
      "2                                 Filling level (cm)                                                                                                 122                                                                                                 141                                                                                                 160                                                                                                 179\n",
      "3                                 Filling width (cm)                                                                                                 284                                                                                                 284                                                                                                 284                                                                                                 284\n",
      "4                                Hopper's width (cm)                                                                                                 290                                                                                                 290                                                                                                 290                                                                                                 290\n",
      "-------------------------------------\n",
      "\n",
      "--- Document 2 (Distance: 0.7783) ---\n",
      "8                          Maximum total weight (kg)                                                                                                4895                                                                                                4895                                                                                                4895                                                                                                4895\n",
      "9                                      Hopper weight                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "10                         Without hopper cover (kg)                                                                                               277,5                                                                                               307,5                                                                                               337,5                                                                                               367,5\n",
      "11                            With hopper cover (kg)                                                                                               324,5                                                                                               354,5                                                                                               384,5                                                                                               414,5\n",
      "12                   With electric hopper cover (kg)                                                                                                                                                                                                     365                                                                                                 395                                                                                                 425\n",
      "13                                         Spreading\n",
      "-------------------------------------\n",
      "\n",
      "--- Document 3 (Distance: 0.9123) ---\n",
      "Getting familiar with the machine\n",
      "Technical specifications\n",
      "                                                           0                                                                        1                                                                        2\n",
      "0                                       Exacta-TLX GEOSPREAD                                                     Exacta-TLX GEOSPREAD                                                     Exacta-TLX GEOSPREAD\n",
      "1                                                Sound level                                                             Closed cabin                                                       Rear window opened\n",
      "2                                    Tractor at 540 rpm (dB)                                                                     71.9                                                                     76.2\n",
      "3                   Tractor + operating, empty spreader (dB)                                                                     71.9                                                                     82.3\n",
      "4                Tractor + spreading spreader (Kali 60) (dB)                                                                     73.8                                                                     84.6\n",
      "5  Tractor + spreading spreader (Kali 60) + Ex- actLine (dB)                                                                     73.0                                                                     87.2\n",
      "6                                              Miscellaneous                                                            Miscellaneous                                                            Miscellaneous\n",
      "7                                         Tractor power (kW)\n",
      "-------------------------------------\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Retrieve Context ---\n",
    "print(f\"[INFO] Attempting to connect to ChromaDB at: {db_path}\")\n",
    "retrieved_docs = []\n",
    "retrieved_distances = []\n",
    "context_string = \"\"\n",
    "collection = None\n",
    "\n",
    "try:\n",
    "    if not db_path.exists() or not db_path.is_dir():\n",
    "        raise FileNotFoundError(f\"ChromaDB directory not found: {db_path}. Please ensure the database has been created.\")\n",
    "\n",
    "    # Initialize ChromaDB Client\n",
    "    chroma_client = chromadb.PersistentClient(path=str(db_path))\n",
    "    print(\"[INFO] ChromaDB client initialized.\")\n",
    "\n",
    "    # Try to get the collection directly - this is the check for existence\n",
    "    print(f\"[INFO] Attempting to get collection: '{dynamic_collection_name}'\")\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(name=dynamic_collection_name)\n",
    "        print(f\"[INFO] Successfully connected to collection '{dynamic_collection_name}'. It contains {collection.count()} items.\")\n",
    "    except Exception as get_collection_error:\n",
    "        # Collection likely doesn't exist or another error occurred\n",
    "        print(f\"[DEBUG] Failed to get collection '{dynamic_collection_name}': {get_collection_error}\") # Log the specific error\n",
    "        # Try listing collections *only* for the error message\n",
    "        available_collections_str = \"(Could not list collections)\"\n",
    "        try:\n",
    "            existing_collections_objects = chroma_client.list_collections()\n",
    "            existing_collection_names = [col.name for col in existing_collections_objects]\n",
    "            available_collections_str = \", \".join(existing_collection_names) if existing_collection_names else \"None\"\n",
    "        except Exception as list_error:\n",
    "            print(f\"[WARNING] Also failed to list collections after failing to get one: {list_error}\")\n",
    "        \n",
    "        # Raise a clear, user-friendly error including the original error\n",
    "        raise ValueError(f\"Collection '{dynamic_collection_name}' not found or could not be accessed in the database at {db_path}. Available collections: [{available_collections_str}]. Ensure it was created with the correct language, chunk size ({chunk_size}), and overlap ({overlap_size}). Original error: {get_collection_error}\")\n",
    "\n",
    "    # --- If collection was successfully retrieved, proceed --- \n",
    "\n",
    "    # Initialize Retriever and Vectorize Question\n",
    "    print(\"[INFO] Initializing embedding retriever...\")\n",
    "    # TODO: Make embedding model configurable if needed, aligning with create_databases.py\n",
    "    retriever = EmbeddingRetriever() # Uses default model\n",
    "    print(\"[INFO] Vectorizing question...\")\n",
    "    question_embedding = retriever.vectorize_text(your_question)\n",
    "\n",
    "    # Ensure correct embedding format for ChromaDB query (List[List[float]])\n",
    "    if isinstance(question_embedding, list) and len(question_embedding) == 1 and isinstance(question_embedding[0], list):\n",
    "        query_vector = question_embedding[0]\n",
    "    else:\n",
    "        # Should not happen with current EmbeddingRetriever, but good practice\n",
    "        raise TypeError(\"Unexpected embedding format received from retriever.\")\n",
    "    print(\"[INFO] Question vectorized successfully.\")\n",
    "\n",
    "    # Retrieve Context\n",
    "    print(f\"[INFO] Retrieving top {top_k} relevant documents...\")\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_vector], # Query expects List[List[float]]\n",
    "        n_results=top_k,\n",
    "        include=[\"documents\", \"distances\"] # Include distances for info\n",
    "    )\n",
    "    print(\"[INFO] Retrieval complete.\")\n",
    "\n",
    "    # Extract results\n",
    "    retrieved_docs = results.get(\"documents\", [[]])[0]\n",
    "    retrieved_distances = results.get(\"distances\", [[]])[0]\n",
    "    context_string = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] An error occurred during context retrieval: {e}\")\n",
    "    # Optionally re-raise to stop notebook execution\n",
    "    # raise\n",
    "\n",
    "# --- Display Context ---\n",
    "print(\"\\n\" + \"=\" * 20 + \" Retrieved Context \" + \"=\" * 20)\n",
    "if not retrieved_docs:\n",
    "    print(\"No relevant documents found.\")\n",
    "else:\n",
    "    for i, (doc, dist) in enumerate(zip(retrieved_docs, retrieved_distances)):\n",
    "        print(f\"\\n--- Document {i + 1} (Distance: {dist:.4f}) ---\")\n",
    "        print(doc)\n",
    "        print(\"-\" * (len(f\"--- Document {i + 1} (Distance: {dist:.4f}) ---\")))\n",
    "print(\"=\" * 59) # Match length of header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Querying LLM: qwen2.5_7B-128k...\n",
      "[INFO] Determined LLM type: ollama\n",
      "[INFO] LLM connector obtained for qwen2.5_7B-128k.\n",
      "[INFO] Sending request to LLM...\n",
      "[INFO] Received response from LLM.\n",
      "\n",
      "--- LLM Answer ---\n",
      "337.5 kg\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# --- (Optional) LLM Query ---\n",
    "llm_answer = None\n",
    "\n",
    "if llm_model_to_use:\n",
    "    print(f\"\\n[INFO] Querying LLM: {llm_model_to_use}...\")\n",
    "    if not context_string:\n",
    "        print(\"[WARNING] No context was retrieved. Querying LLM without context.\")\n",
    "        # context_string = \"No context available.\" # Or handle as needed\n",
    "\n",
    "    try:\n",
    "        # Initialize LLM Manager\n",
    "        llm_connector_manager = LLMConnectorManager(llm_models_config)\n",
    "\n",
    "        # Determine LLM type\n",
    "        llm_type = find_llm_type(llm_model_to_use, llm_models_config)\n",
    "        if not llm_type:\n",
    "            # Add more robust checking like in ask_question.py if needed\n",
    "            raise ValueError(f\"LLM '{llm_model_to_use}' not found in configuration under 'llm_models'.\")\n",
    "        print(f\"[INFO] Determined LLM type: {llm_type}\")\n",
    "\n",
    "        # Get LLM Connector\n",
    "        llm_connector = llm_connector_manager.get_connector(llm_type, llm_model_to_use)\n",
    "        print(f\"[INFO] LLM connector obtained for {llm_model_to_use}.\")\n",
    "\n",
    "        # Load Question Prompt\n",
    "        question_prompt_template = config_loader.load_prompt_template(\"question_prompt\")\n",
    "\n",
    "        # Format Prompt\n",
    "        formatted_prompt = question_prompt_template.format(\n",
    "            context=context_string, question=your_question\n",
    "        )\n",
    "        # print(f\"\\n[DEBUG] Formatted Prompt:\\n{formatted_prompt}\\n\") # Uncomment for debugging\n",
    "\n",
    "        # Invoke LLM\n",
    "        print(\"[INFO] Sending request to LLM...\")\n",
    "        llm_answer = llm_connector.invoke(formatted_prompt)\n",
    "        print(\"[INFO] Received response from LLM.\")\n",
    "\n",
    "        # Display Answer\n",
    "        print(\"\\n--- LLM Answer ---\")\n",
    "        print(llm_answer)\n",
    "        print(\"------------------\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"[ERROR] Prompt file error: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"[ERROR] Configuration or LLM setup error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error during LLM interaction: {e}\")\n",
    "        llm_answer = None # Ensure answer is None if error occurred\n",
    "else:\n",
    "    print(\"\\n[INFO] LLM query skipped as no model was specified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating LLM Answer ---\n",
      "[INFO] Evaluator initialized with model: gemma3_12B-128k\n",
      "[INFO] Sending request to Evaluator LLM...\n",
      "[INFO] Received response from Evaluator LLM.\n",
      "\n",
      "--- Evaluation Result (Expected: 'What is the hopper weight without hopper cover in kg of the Exacta-TLX GEOSPREAD 3225') ---\n",
      "Judgment: no\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- (Optional) Evaluate Answer ---\n",
    "evaluation_result = None\n",
    "\n",
    "if evaluate_answer_flag:\n",
    "    if not llm_model_to_use:\n",
    "        print(\"\\n[INFO] Evaluation skipped: No LLM was used to generate an answer.\")\n",
    "    elif llm_answer is None:\n",
    "        print(\"\\n[INFO] Evaluation skipped: Failed to get an answer from the LLM.\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluating LLM Answer ---\")\n",
    "        try:\n",
    "            expected_answer = input(\"Please provide the expected answer for evaluation: \")\n",
    "\n",
    "            # Initialize Evaluator\n",
    "            evaluator_model_name = config_loader.get_evaluator_model_name()\n",
    "            if not evaluator_model_name:\n",
    "                raise ValueError(\"Evaluator model name not found in config. Cannot evaluate.\")\n",
    "\n",
    "            evaluator_llm_type = find_llm_type(evaluator_model_name, llm_models_config)\n",
    "            if not evaluator_llm_type:\n",
    "                evaluator_llm_type = DEFAULT_EVALUATOR_LLM_TYPE\n",
    "                print(f\"[WARNING] Could not determine type for evaluator '{evaluator_model_name}'. Assuming '{evaluator_llm_type}'.\")\n",
    "\n",
    "            # Need LLM manager again if not created before (e.g., if LLM query cell was skipped but eval is true)\n",
    "            if 'llm_connector_manager' not in locals():\n",
    "                 llm_connector_manager = LLMConnectorManager(llm_models_config)\n",
    "\n",
    "            evaluator_llm_connector = llm_connector_manager.get_connector(\n",
    "                evaluator_llm_type, evaluator_model_name\n",
    "            )\n",
    "            evaluation_prompt_template = config_loader.load_prompt_template(\"evaluation_prompt\")\n",
    "\n",
    "            evaluator = Evaluator(evaluator_llm_connector, evaluation_prompt_template)\n",
    "            print(f\"[INFO] Evaluator initialized with model: {evaluator_model_name}\")\n",
    "\n",
    "            # Perform Evaluation\n",
    "            print(\"[INFO] Sending request to Evaluator LLM...\")\n",
    "            evaluation_result = evaluator.evaluate_answer(\n",
    "                question=your_question,\n",
    "                model_answer=llm_answer,\n",
    "                expected_answer=expected_answer,\n",
    "            )\n",
    "            print(\"[INFO] Received response from Evaluator LLM.\")\n",
    "\n",
    "            # Display Evaluation Result\n",
    "            print(f\"\\n--- Evaluation Result (Expected: '{expected_answer}') ---\")\n",
    "            print(f\"Judgment: {evaluation_result}\")\n",
    "            print(\"----------------------------------------------------\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"[ERROR] Evaluation prompt file error: {e}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"[ERROR] Configuration or Evaluator setup error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error during evaluation: {e}\")\n",
    "else:\n",
    "    print(\"\\n[INFO] Evaluation skipped as requested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Finished\n",
    "\n",
    "The script has completed its execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
