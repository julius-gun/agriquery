\begin{table}[!htbp]
\caption{Performance of English Hybrid Models}
\label{tab:english_hybrid_performance}
  \footnotesize
\begin{tabular}{lccccc}
\toprule
Metric & Acc. & F1 & Prec. & Rec. & Spec. \\
LLM &  &  &  &  &  \\
\midrule
\midrule
Gemini 2.5 Flash & \textbf{0.880} & \textbf{0.889} & 0.825 & \textbf{0.963} & 0.796 \\
Qwen 2.5 7B & 0.861 & 0.867 & \textbf{0.831} & 0.907 & \textbf{0.815} \\
Qwen3 8B & 0.815 & 0.821 & 0.793 & 0.852 & 0.778 \\
Phi3 14B & 0.796 & 0.810 & 0.758 & 0.870 & 0.722 \\
Llama3.1 8B & 0.796 & 0.817 & 0.742 & 0.907 & 0.685 \\
Deepseek-R1 8B & 0.759 & 0.790 & 0.700 & 0.907 & 0.611 \\
Llama3.2 3B & 0.852 & 0.857 & 0.828 & 0.889 & \textbf{0.815} \\
Deepseek-R1 1.5B & 0.630 & 0.677 & 0.600 & 0.778 & 0.481 \\
Llama3.2 1B & 0.500 & 0.614 & 0.500 & 0.796 & 0.204 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[!htbp]
\caption{Performance of French Hybrid Models}
\label{tab:french_hybrid_performance}
  \footnotesize
\begin{tabular}{lccccc}
\toprule
Metric & Acc. & F1 & Prec. & Rec. & Spec. \\
LLM &  &  &  &  &  \\
\midrule
\midrule
Gemini 2.5 Flash & 0.824 & 0.826 & 0.818 & \textbf{0.833} & 0.815 \\
Qwen 2.5 7B & \textbf{0.852} & \textbf{0.840} & \textbf{0.913} & 0.778 & \textbf{0.926} \\
Qwen3 8B & 0.741 & 0.725 & 0.771 & 0.685 & 0.796 \\
Phi3 14B & 0.759 & 0.759 & 0.759 & 0.759 & 0.759 \\
Llama3.1 8B & 0.815 & 0.818 & 0.804 & \textbf{0.833} & 0.796 \\
Deepseek-R1 8B & 0.685 & 0.696 & 0.672 & 0.722 & 0.648 \\
Llama3.2 3B & 0.806 & 0.796 & 0.837 & 0.759 & 0.852 \\
Deepseek-R1 1.5B & 0.602 & 0.619 & 0.593 & 0.648 & 0.556 \\
Llama3.2 1B & 0.491 & 0.574 & 0.493 & 0.685 & 0.296 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[!htbp]
\caption{Performance of German Hybrid Models}
\label{tab:german_hybrid_performance}
  \footnotesize
\begin{tabular}{lccccc}
\toprule
Metric & Acc. & F1 & Prec. & Rec. & Spec. \\
LLM &  &  &  &  &  \\
\midrule
\midrule
Gemini 2.5 Flash & \textbf{0.870} & \textbf{0.865} & \textbf{0.900} & \textbf{0.833} & \textbf{0.907} \\
Qwen 2.5 7B & 0.796 & 0.780 & 0.848 & 0.722 & 0.870 \\
Qwen3 8B & 0.824 & 0.819 & 0.843 & 0.796 & 0.852 \\
Phi3 14B & 0.769 & 0.762 & 0.784 & 0.741 & 0.796 \\
Llama3.1 8B & 0.769 & 0.766 & 0.774 & 0.759 & 0.778 \\
Deepseek-R1 8B & 0.704 & 0.714 & 0.690 & 0.741 & 0.667 \\
Llama3.2 3B & 0.759 & 0.745 & 0.792 & 0.704 & 0.815 \\
Deepseek-R1 1.5B & 0.574 & 0.596 & 0.567 & 0.630 & 0.519 \\
Llama3.2 1B & 0.463 & 0.540 & 0.472 & 0.630 & 0.296 \\
\bottomrule
\end{tabular}
\end{table}