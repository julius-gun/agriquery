\begin{table}[!htbp]
\caption{Performance of English Keyword Models}
\label{tab:english_keyword_performance}
  \footnotesize
\begin{tabular}{lccccc}
\toprule
Metric & Acc. & F1 & Prec. & Rec. & Spec. \\
LLM &  &  &  &  &  \\
\midrule
\midrule
Gemini 2.5 Flash & \textbf{0.852} & \textbf{0.849} & \textbf{0.865} & \textbf{0.833} & \textbf{0.870} \\
Qwen 2.5 7B & 0.824 & 0.816 & 0.857 & 0.778 & \textbf{0.870} \\
Qwen3 8B & 0.815 & 0.818 & 0.804 & \textbf{0.833} & 0.796 \\
Phi3 14B & 0.787 & 0.777 & 0.816 & 0.741 & 0.833 \\
Llama3.1 8B & 0.787 & 0.789 & 0.782 & 0.796 & 0.778 \\
Deepseek-R1 8B & 0.731 & 0.743 & 0.712 & 0.778 & 0.685 \\
Llama3.2 3B & 0.796 & 0.788 & 0.820 & 0.759 & 0.833 \\
Deepseek-R1 1.5B & 0.630 & 0.643 & 0.621 & 0.667 & 0.593 \\
Llama3.2 1B & 0.463 & 0.574 & 0.476 & 0.722 & 0.204 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[!htbp]
\caption{Performance of French Keyword Models}
\label{tab:french_keyword_performance}
  \footnotesize
\begin{tabular}{lccccc}
\toprule
Metric & Acc. & F1 & Prec. & Rec. & Spec. \\
LLM &  &  &  &  &  \\
\midrule
\midrule
Gemini 2.5 Flash & \textbf{0.583} & 0.328 & 0.846 & 0.204 & 0.963 \\
Qwen 2.5 7B & 0.556 & 0.273 & 0.750 & 0.167 & 0.944 \\
Qwen3 8B & 0.556 & 0.294 & 0.714 & 0.185 & 0.926 \\
Phi3 14B & 0.546 & 0.310 & 0.647 & 0.204 & 0.889 \\
Llama3.1 8B & \textbf{0.583} & \textbf{0.348} & 0.800 & \textbf{0.222} & 0.944 \\
Deepseek-R1 8B & 0.491 & 0.267 & 0.476 & 0.185 & 0.796 \\
Llama3.2 3B & 0.565 & 0.230 & \textbf{1.000} & 0.130 & \textbf{1.000} \\
Deepseek-R1 1.5B & 0.389 & 0.233 & 0.312 & 0.185 & 0.593 \\
Llama3.2 1B & 0.213 & 0.206 & 0.208 & 0.204 & 0.222 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[!htbp]
\caption{Performance of German Keyword Models}
\label{tab:german_keyword_performance}
  \footnotesize
\begin{tabular}{lccccc}
\toprule
Metric & Acc. & F1 & Prec. & Rec. & Spec. \\
LLM &  &  &  &  &  \\
\midrule
\midrule
Gemini 2.5 Flash & 0.528 & 0.190 & 0.667 & 0.111 & 0.944 \\
Qwen 2.5 7B & \textbf{0.537} & 0.138 & \textbf{1.000} & 0.074 & \textbf{1.000} \\
Qwen3 8B & \textbf{0.537} & 0.194 & 0.750 & 0.111 & 0.963 \\
Phi3 14B & 0.528 & 0.164 & 0.714 & 0.093 & 0.963 \\
Llama3.1 8B & 0.519 & 0.161 & 0.625 & 0.093 & 0.944 \\
Deepseek-R1 8B & 0.472 & 0.174 & 0.400 & 0.111 & 0.833 \\
Llama3.2 3B & 0.509 & 0.102 & 0.600 & 0.056 & 0.963 \\
Deepseek-R1 1.5B & 0.306 & 0.096 & 0.138 & 0.074 & 0.537 \\
Llama3.2 1B & 0.398 & \textbf{0.198} & 0.296 & \textbf{0.148} & 0.648 \\
\bottomrule
\end{tabular}
\end{table}